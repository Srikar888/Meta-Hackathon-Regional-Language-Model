# Regional Language Model Implementation using Meta Llama 3.2 - Rashividya

**TEAM: RML LANGUAGE CULTS
**

Srikar Gundu - Developer
Bharath B M - Quality Assurance


# Meta-Hackathon-Regional-Language-Model
This repository showcases the work done For Reskilll AI Hackathon using a fine tuned AI Llama Model Trained using Document as a Dataset to train Meta Llama 3.2-1B Parameters in Regional Languages

# Solution Proposed

Fine tuning the existing Llama 3.2 -1B (1 Billion Parameters) model by using a specific set of documents and dataset through data extraction with large data set containing more than 10000 characters through using GROQ for free API Key Access and llama-index and hugging face for implementing model for custom query generation from existing training data processed to avoid overfitting and using AWS BedRock for further speeding up the document testing process 

# Problem Statement

Theme: AI For Societal Good - Build for Bharat

Problem Statement:
Fine-Tuning AI Llama 3.2-1B Model to train based on Regional Languages to Learn , Gain Access and Increase Support for End to End User Conversations and further optimized for Chat Based Solutions

# USP (Unique Selling Point)

The Unique Selling Point for this proposed solution is training Meta Llama 3.2-1B itself instead of building on it like a wrapper but training it through documents so base model recognises regional language characters and generates vector tokens as we use RAG Processing through llama-index so we can train base model which can be used to create assistant models thus improving chat and capabilities of the original model when deployed in future.

# Tech Stack (Implementation)

Python (Language)

Packages Used: 
1.llama-index
2.llama-index-llms-groq
3.groq
4.llama-index-embeddings-huggingface

# Demo Video

https://drive.google.com/file/d/1zBHbwr8s-vGJmZ9zxQyeNmWfeIWrLjce/view?usp=sharing

# Future Scope

We can further implement and use multiple documents for training model and thus increasing and provided more attention-based context to train meta llama model 3.2 -1B Parameters model where we can create assistant models as we are using verified answers to train the answers and thus a reward point system can be used in assistant model  which can be used for end to end conversation and thus solve and provide solutions in regional languages as well.



